<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.4/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300&family=Tenor+Sans&display=swap" rel="stylesheet">
    <script src="https://kit.fontawesome.com/7c463d890f.js" crossorigin="anonymous"></script>

       <!-- Your other head content here -->
    <script>
     function showJsonPopup(event) {
    event.preventDefault(); // Prevent default link behavior
    // Fetch JSON data
    fetch('./table_data.json')
        .then(response => response.json())
        .then(data => {
            // Construct JSON content string
            let content = '<ul>';
            for (const [key, value] of Object.entries(data)) {
                content += `<li><strong>${key}:</strong> ${JSON.stringify(value)}</li>`;
            }
            content += '</ul>';
            // Create popup window
            const popupWindow = window.open('', '_blank', 'width=600,height=400,scrollbars=yes,resizable=yes');
            popupWindow.document.write(`<html><head><title>JSON Data</title></head><body>${content}</body></html>`);
        })
        .catch(error => console.error('Error loading JSON:', error));
}
  </script>




    <title>CPLIP</title>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-KT5YTF7856"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'G-KT5YTF7856');
    </script>  
    <link rel="icon" type="image/x-icon" href="img/quilt1m.png">

    <style>
        .quilt{
        
        font-variant: small-caps;
        font-family: 'Latin Modern Roman', serif;
    
        }
        .div1{
            background-color:#f1fcec;
            border-radius: 15px;
        }

        .div2{
          display: block;
          padding: 9.5px;
          margin: 0 0 10px;
          font-size: 14px;
          line-height: 1.42857143;
          word-break: break-all;
          word-wrap: break-word;
          color: #333;
          background-color: #f5f5f5;
          border: 1px solid #ccc;
          border-radius: 4px;
        }

        .divtext1{
            font-size: 40px;
        }

        .font1{
            font-family: 'Tenor Sans', sans-serif;
        }

        .font2{
            font-family: 'Roboto', sans-serif;
        }

        .btndes{
          border-radius: 20px;
          background-color: #363636;
          color: white;
          text-decoration: none !important;
        }

        .btndes:hover {
          background-color:black;
          color: white;
        }

        .navsize1{
            font-size: 25px;
        }
        .navsize{
            font-size: 18px;;
        }
        .absfont{
            font-size: 17px;;
        }

        .navcolor{
            background-color: #363636;
        }

        .navfontc{
            color: white;
        }

        .margin-left{
            margin-left: 10px;
        }

        .size2{
            font-size: 23px;
        }

        .datalink{
            background-color:#E2E0E4;
            border-radius: 10px;

        }

        .margin{
            margin-left: 10px;
            font-size: 15px;
        }

        .card {
            box-shadow: 0 2px 5px 0 rgba(0, 0, 0, 0.16), 0 2px 10px 0 rgba(0, 0, 0, 0.12);
        }

        .card {
          margin-top: 10px;
          box-sizing: border-box;
          border-radius: 2px;
          background-clip: padding-box;
          min-height:200px;
        }

        .card span.card-title {
          color: #fff;
          font-size: 24px;
          font-weight: 300;
          text-transform: uppercase;
        }

        .card .card-image {
          position: relative;
          overflow: hidden;
        }

        .card .card-image img {
          border-radius: 2px 2px 0 0;
          background-clip: padding-box;
          position: relative;
          z-index: -1;
        }

        .card .card-image span.card-title {
          position: absolute;
          bottom: 0;
          left: 0;
          padding: 16px;
        }

        .card .card-content {
          padding: 10px;
          border-radius: 0 0 2px 2px;
          background-clip: padding-box;
          box-sizing: border-box;
        }

        .card .card-content p {
          margin: 0;
          color: inherit;
        }

        .card .card-content span.card-title {
          line-height: 48px;
        }

        .card .card-action {
          border-top: 1px solid rgba(160, 160, 160, 0.2);
          padding: 16px;
        }

        .card .card-action a {
          color: #ffab40;
          margin-right: 16px;
          transition: color 0.3s ease;
          text-transform: uppercase;
        }

        .card .card-action a:hover {
          color: #ffd8a6;
          text-decoration: none;
        }
    </style>
  </head>
  <body>
  <nav class="navbar navbar-inverse navcolor">
    <div class="container-fluid">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>                        
        </button>
        <a class="navbar-brand font1 navsize1" href="https://cplip.github.io/"><span class="quilt">CPLIP</span></a>
      </div>
      <div class="collapse navbar-collapse" id="myNavbar">
        <ul class="nav navbar-nav navsize">
          <!-- <li><a href="https://arxiv.org/abs/2306.11207">Paper</a></li> -->
          <li><a href="#dataset">Dictionary</a></li>
          <li><a href="#result">Results</a></li>
          <!-- <li><a href="#author">Authors</a></li> -->
          <li><a href="#cite">Citation</a></li>
          <li><a href="#contact">Contact</a></li>
        </ul>
      </div>
    </div>
  </nav>
  <div class="container div1" align="center">
      <h1 class="divtext1 font1"><b><span class="quilt"><span class="quilt"><span class="quilt">CPLIP</span></span></span>: Zero-Shot Learning for Histopathology with Comprehensive Vision-Language Alignment <br><br> <span><h2>CVPR 2024</h2></span> </b></h1> <br>
      
    <h3 class="font2">
    Sajid Javed<sup>1</sup>, Arif Mahmood<sup>2</sup>, Iyyakutti Iyappan Ganapathi<sup>1*</sup>, <br>
    Fayaz Ali Dharejo<sup>1</sup>, Naoufel Werghi<sup>1*</sup>, Mohammed Bennamoun<sup>3</sup>
</h3>

<p>
    <sup>1</sup> Department of Computer Science Department & C2PS*, Khalifa University, Abu Dhabi, UAE<br>
    <sup>2</sup> Information Technology University, Lahore, Pakistan<br>        
    <sup>3</sup> The University of Western Australia, Perth, Australia
</p>
    
      <!-- <h4 class="font2"><img src="img/quilt1m.png" height="20px" alt="">- Equal Contribution</h5> <br> -->
      <!-- <a class="btn  navsize margin-left btndes" href="" role="button"> Paper  <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 384 512">! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2023 Fonticons, Inc.<path d="M0 64C0 28.7 28.7 0 64 0H224V128c0 17.7 14.3 32 32 32H384V448c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V64zm384 64H256V0L384 128z"/></svg></a>  -->
      <a class="btn  navsize margin-left btndes" href="https://github.com/iyyakuttiiyappan/CPLIP" role="button"> Code  <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2023 Fonticons, Inc. --><style>svg{fill:#fdfcfc}</style><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a>
      <a class="btn  navsize margin-left btndes" href="https://github.com/iyyakuttiiyappan/CPLIP" role="button"> Data  <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 576 512">! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2023 Fonticons, Inc.<path d="M160 32c-35.3 0-64 28.7-64 64V320c0 35.3 28.7 64 64 64H512c35.3 0 64-28.7 64-64V96c0-35.3-28.7-64-64-64H160zM396 138.7l96 144c4.9 7.4 5.4 16.8 1.2 24.6S480.9 320 472 320H328 280 200c-9.2 0-17.6-5.3-21.6-13.6s-2.9-18.2 2.9-25.4l64-80c4.6-5.7 11.4-9 18.7-9s14.2 3.3 18.7 9l17.3 21.6 56-84C360.5 132 368 128 376 128s15.5 4 20 10.7zM192 128a32 32 0 1 1 64 0 32 32 0 1 1 -64 0zM48 120c0-13.3-10.7-24-24-24S0 106.7 0 120V344c0 75.1 60.9 136 136 136H456c13.3 0 24-10.7 24-24s-10.7-24-24-24H136c-48.6 0-88-39.4-88-88V120z"/></svg></a>
      <!-- <a class="btn  navsize margin-left btndes" href="" role="button"> Model/ Demo  <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 448 512">! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2023 Fonticons, Inc.<path d="M160 80c0-26.5 21.5-48 48-48h32c26.5 0 48 21.5 48 48V432c0 26.5-21.5 48-48 48H208c-26.5 0-48-21.5-48-48V80zM0 272c0-26.5 21.5-48 48-48H80c26.5 0 48 21.5 48 48V432c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V272zM368 96h32c26.5 0 48 21.5 48 48V432c0 26.5-21.5 48-48 48H368c-26.5 0-48-21.5-48-48V144c0-26.5 21.5-48 48-48z"/></svg></a> -->
      <br><br>
  </div>
  <br><br>
  <div class="container">
      <h1>Abstract</h1> <br>
      <p class="absfont"> This paper proposes Comprehensive Pathology Language Image Pre-training <span class="quilt">(CPLIP)</span>, 
        a new unsupervised technique designed to enhance the alignment 
        of images and text in histopathology for tasks such as classification and segmentation. This methodology 
        enriches vision-language models by leveraging extensive data without needing ground truth annotations. 
        <span class="quilt">CPLIP</span> involves constructing a pathology-specific dictionary, generating textual descriptions for images 
        using language models, and retrieving relevant images for each text snippet via a pre-trained model. 
The model is then fine-tuned using a many-to-many contrastive learning method to align complex interrelated concepts across both modalities.
Evaluated across multiple histopathology tasks, <span class="quilt">CPLIP</span> shows notable improvements in zero-shot learning scenarios, outperforming existing methods in both interpretability and robustness and setting a higher benchmark for the application of vision-language models in the field.
      </p>
  </div>
  <br><br>
  <div class="container">
      <h1>The Proposed Model</h1> <br> 
      <div class="text-center">
          <img class="img-fluid" src="mainFigure.png" style="max-width: 99%;" alt="...">
        </div> <br><br> 
      <p class="absfont">
        
This work introduces the CPLIP algorithm, which leverages unlabeled histology images and a pathology 
prompt dictionary to fine-tune the CLIP model without any annotations. This adaptation aims to enhance 
CLIP's performance across diverse histology data, enabling transfer learning for different pathology tasks. <br>
<br>       
In computational pathology, VL models have evolved from being novel to indispensable, 
        allowing fine-tuning on smaller datasets compared to VL pretraining. However, the scarcity 
        of Whole Slide Images (WSIs) and 
        diverse cancer morphologies presents challenges for zero-shot transfer tasks, such as 
        patch-based tissue recognition and WSI-level cancer subtyping. Despite this, VL models 
        have been successfully deployed in classifying and analyzing WSIs, revolutionizing computational pathology.

        Textual prompts are crucial for improving VL model performance, but their reliance on single phrases 
        for each histology image may limit zero-shot classification effectiveness. Introducing richer, 
        more detailed prompts could broaden VL models' understanding of various cancer types.
        
        Currently, existing histology VL models do not incorporate diverse textual prompts 
        during training or at the inference stage. Unlike existing methods focusing on aligning 
        individual textual and visual concepts, our approach proposes simultaneous alignment of 
        numerous interrelated textual and visual concepts.
      </p>
  </div>
  <br>
  <div class="container" id="dataset">
      <h1>Dictionary</h1> <br>
      <p class="absfont">

        The ARCH dataset, the main source of histology image-caption pairs, has limitations as it requires 
        paired data. To overcome this, we propose a pathology prompt dictionary to extract comprehensive 
        image-text descriptions.
        <br><br>
    Our dictionary, curated from reputable cancer glossaries<sup>
        <a href="https://lab-ally.com/histopathology-resources/histopathology-glossary/" target="_blank">1</a> & 
        <a href="https://www.cancer.org/cancer/understanding-cancer/glossary.html" target="_blank">2</a>
    </sup>, covers a wide range of cancer types and morphologies.
    <br><br>
    <!-- Link to trigger popup -->
    <a href="#" onclick="showJsonPopup(event)">View JSON Data</a>
    <br><br>
We compared it with another vocabulary, refining it to include 700 terms related specifically to histopathology.
 The refined dictionary aims to aid diagnosis by providing succinct prompts for major cancer types and
  morphologies.  
    </p>
  </div>
      <!-- <div class="embed-responsive embed-responsive-16by9">
        <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/NklNJ2Z4wMM" allowfullscreen></iframe>
      </div> -->
      <br> 
      <div class="container" id="result">
      <h1>Results</h1> <br>
      <p class="absfont">  A comparative assessment of zero-shot classification performance is conducted, contrasting the novel CPLIP algorithm with state-of-the-art methods including 
        <a href="https://ar5iv.labs.arxiv.org/html/2303.00915" target="_blank">BiomedCLIP</a>, 
        <a href="https://www.nature.com/articles/s41591-023-02504-3" target="_blank">PLIP</a>, 
        and 
        <a href="https://arxiv.org/abs/2306.07831" target="_blank">MI-Zero</a>. 
        The analysis, based on weighted F1 scores, illustrates CPLIP's significant performance improvements across six distinct histology datasets.  
        <br> <br></p>
      </div>

      <div class="text-center">
          <img class="img-fluid" src="intro_accuracy_comparison-1.jpg" style="max-width: 50%" alt="...">
        </div> <br><br> 

  
  
  <!-- <div class="container" id="author">
      <h1>Authors</h1> <br> <br>
      <div class="container">
          <div class="row">
              <center>
            <div class="col-sm-2">
              <div class="card">
                <div class="card-image">
                  <img class="img-responsive" src="img/wisdom.jpeg">
                </div>
        
                <div class="card-content">
                  <p>Wisdom O. Ikezogwo <img src="img/quilt1m.png" height="15px" alt=""></p>
                </div>
              </div>
            </div>
            <div class="col-sm-2">
              <div class="card">
                <div class="card-image">
                  <img class="img-responsive" src="img/saygin.png">
                </div>
        
                <div class="card-content">
                  <p>M. Saygin Seyfioglu <img src="img/quilt1m.png" height="15px" alt=""></p>
                </div>
              </div>
            </div>
            <div class="col-sm-2">
              <div class="card">
                <div class="card-image">
                  <img class="img-responsive" src="img/fatemeh.JPG">
                </div>
        
                <div class="card-content">
                  <p>Fatemeh Ghezloo <img src="img/quilt1m.png" height="15px" alt=""></p>
                </div>
              </div>
            </div>
            <div class="col-sm-2">
              <div class="card">
                <div class="card-image">
                  <img class="img-responsive" src="img/dylan.jpeg">
                </div> 
        
                <div class="card-content">
                  <p>Dylan Geva</p>
                </div>
              </div>
            </div>
            <div class="col-sm-2">
              <div class="card">
                <div class="card-image">
                  <img class="img-responsive" src="img/fatwir.jpeg">
                </div>
        
                <div class="card-content">
                  <p>Fatwir S. Mohammed</p>
                </div>
              </div>
            </div>
                      <div class="col-sm-2">
              <div class="card">
                <div class="card-image">
                  <img class="img-responsive" src="img/pavan.jpeg">
                </div>
        
                <div class="card-content">
                  <p>Pavan K. Anand</p>
                </div>
              </div>
            </div>
            
            <div class="col-sm-2">
              <div class="card">
                <div class="card-image">
                  <img class="img-responsive" src="img/ranjay.jpeg">
                </div>
        
                <div class="card-content">
                  <p>Ranjay Krishna</p>
                </div>
              </div>
            </div>
            <div class="col-sm-2">
              <div class="card">
                <div class="card-image">
                  <img class="img-responsive" src="img/linda.jpeg">
                </div>
        
                <div class="card-content">
                  <p>Linda Shapiro</p>
                </div>
              </div>
            </div>
          </center>
          </div>
        
        </div>
      
        <br><br>
        <center>
        <h4 class="font2"><img src="img/quilt1m.png" height="20px" alt="">- Equal First Author Contribution</h4> <br></center>

  </div> -->


  <br><br>
  <div class="container" id="cite">
    <h1>Citation</h1> <br> 
    If you use the findings of this research in your work, please cite our paper:
    <br>
    <pre class="div2">@article{sajid2024cplip,
      title={CPLIP: Zero-Shot Learning for Histopathology with Comprehensive Vision-Language Alignment},
      author={Sajid Javed, Arif Mahmood, Iyyakutti Iyappan Ganapathi, Fayaz Ali Dharejo1, Naoufel Werghi, Mohammed Bennamoun},      
      booktitle={CVPR},
      year={2024}<!-- journal={arXiv preprint arXiv:2306.11207}, -->
    }</pre>
  </div>
  <br><br>
  <div class="container" id="contact">
      <h1>Contact</h1> <br>
      <p class="absfont">For any inquiries regarding CPLIP or to reach out, please feel free to contact
         Sajid Javed at {sajid.javed at ku.ac.ae} / Iyyakutti Iyappan Ganapathi at {iyyakutti.ganapathi at ku.ac.ae}.</p> <br>
  </div>
  <div class="row align-items-center" >
      <center>    
      <div class="col thumb d-flex align-items-center">
          <img class="img-fluid" src="img/img3.png" style="max-width: 30%;" alt="">
      </div>
      </center>

  </div>
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
  
  
 

  </body>
</html>
